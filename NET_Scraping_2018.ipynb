{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Packages to install:\n",
    "\n",
    "    brew install tcl-tk ghostscript\n",
    "    pip install camelot-py[cv]\n",
    "    pip install PyPDF2\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-10T19:49:26.546167Z",
     "start_time": "2020-02-10T19:49:26.540526Z"
    }
   },
   "outputs": [],
   "source": [
    "import camelot\n",
    "import PyPDF2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from datetime import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-06T23:37:20.041753Z",
     "start_time": "2020-02-06T23:37:20.038386Z"
    }
   },
   "outputs": [],
   "source": [
    "def fetch_table(filename):\n",
    "    soup = BeautifulSoup(open(filename), \"html.parser\")\n",
    "    return soup.findAll('table')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-06T23:37:20.389281Z",
     "start_time": "2020-02-06T23:37:20.383031Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_season_raw_data(target_table):\n",
    "    data_list = []\n",
    "    for row in target_table.find_all('tr'):\n",
    "        row_list = []\n",
    "        for item in row.find_all('th'):\n",
    "            row_list.append(item.text)\n",
    "        for item in row.find_all('td'):\n",
    "            row_list.append(item.text)\n",
    "            try:\n",
    "                row_list.append(item.a['href'])\n",
    "            except:\n",
    "                continue\n",
    "        if len(row_list) == 8 and row_list[-1].replace(' ','') == 'Name':\n",
    "            data_list.append(row_list + ['URL'])\n",
    "        if len(row_list) == 9:\n",
    "            data_list.append(row_list)\n",
    "    return data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-06T23:37:20.723441Z",
     "start_time": "2020-02-06T23:37:20.719973Z"
    }
   },
   "outputs": [],
   "source": [
    "def download_pdf(year, date, url):\n",
    "    f = requests.get(url)\n",
    "    open(f'{str(year)}/{date}.pdf', 'wb').write(f.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-06T23:43:31.882396Z",
     "start_time": "2020-02-06T23:43:31.874825Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_season_net_df(filename, downloaded=True):\n",
    "    target_table = fetch_table(filename)\n",
    "    data_list = get_season_raw_data(target_table)\n",
    "    \n",
    "    cols = [col.lower().strip(' ').replace(' ', '_') \n",
    "            for col in data_list[0]]\n",
    "    df = pd.DataFrame(data_list[1:], columns=cols)\n",
    "    if len(set(df['year'])) != 1:\n",
    "        raise ValueError('Recheck the .html file')\n",
    "    else:\n",
    "        year = list(set(df['year']))[0]\n",
    "    \n",
    "    df = df.drop(['sport', 'division', 'gender', 'year', 'document_type'], axis=1)\n",
    "    df['through_date'] = df['through_date']\\\n",
    "    .apply(lambda x: str(datetime.strptime(x, '%m/%d/%Y'))\n",
    "           .split(' ')[0])\n",
    "    \n",
    "    if downloaded == False:\n",
    "        print('Downloading pdfs...')\n",
    "        for row in df[['through_date', 'url']].values:\n",
    "            download_pdf(year, row[0], row[1])\n",
    "        print('Complete Downloading.')\n",
    "    \n",
    "    df['filename'] = df['through_date'].apply(lambda x: f'{year}/{x}.pdf')\n",
    "    df['page_number'] = df['filename'].apply(lambda x: PyPDF2.PdfFileReader(x).getNumPages())\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-06T23:37:23.319046Z",
     "start_time": "2020-02-06T23:37:23.314804Z"
    }
   },
   "outputs": [],
   "source": [
    "def pdf_to_tables(pdf_filename, num_page):\n",
    "    pages = ','.join([str(x) for x in list(range(1, 1 + num_page))])\n",
    "    tables = camelot.read_pdf(pdf_filename, flavor='stream', pages=pages)\n",
    "    return tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-10T19:50:46.451947Z",
     "start_time": "2020-02-10T19:50:46.437891Z"
    }
   },
   "outputs": [],
   "source": [
    "def tables_to_df(tables, num_page, cols):\n",
    "    df = pd.concat([pd.DataFrame([row for row in tables[i].df.values \n",
    "                                  if '' not in row or '[]' in row], columns=cols)\n",
    "                    for i in range(num_page)])\n",
    "    if df.shape[0] != 353:\n",
    "        raise ValueError(f'There should be 353 teams, not {df.shape[0]}')\n",
    "    else:\n",
    "        if '' in df.columns:\n",
    "            df = df.drop('', axis=1)\n",
    "            df['net_rank'] = [str(i+1) for i in range(df.shape[0])]\n",
    "        if 'sos' not in df.columns:\n",
    "            df['sos'] = np.nan\n",
    "            df['nc_sos'] = np.nan\n",
    "            cols = ['team', 'net_rank', 'avg_opp_net', 'avg_opp_rank',\n",
    "                    'record', 'conf_record', \n",
    "                    'non_conf_record', 'road_record', 'sos', 'nc_sos']  + \\\n",
    "                   [f'quadrant_{i}_record' for i in range(1, 5)]\n",
    "            df = df[cols]\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-10T19:50:48.637364Z",
     "start_time": "2020-02-10T19:50:48.632839Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_net_df(pdf_filename, num_page, cols):\n",
    "    tables = pdf_to_tables(pdf_filename, num_page)\n",
    "    df = tables_to_df(tables, num_page, cols)\n",
    "    df['filename'] = pdf_filename\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-10T18:42:10.933627Z",
     "start_time": "2020-02-10T18:42:10.900630Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_net_cols(pdf_filename):\n",
    "    tables = camelot.read_pdf(pdf_filename, flavor='stream', pages='1')\n",
    "    cols = [row for row in tables[0].df.values if 'Team' in row]\n",
    "    if 'NET' not in cols[0]:\n",
    "        print(f'No NET in this file: {pdf_filename}')\n",
    "        return None\n",
    "    else:\n",
    "        return len(cols[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-06T23:44:18.075197Z",
     "start_time": "2020-02-06T23:44:17.551519Z"
    }
   },
   "outputs": [],
   "source": [
    "# net_df = get_season_net_df('NCAA RPI Archive - Home.htm', downloaded=False)\n",
    "net_df = get_season_net_df('NCAA RPI Archive - Home.htm')\n",
    "# net_df.to_csv('2019_NET.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-10T18:49:02.709397Z",
     "start_time": "2020-02-10T18:49:02.692155Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>report_type</th>\n",
       "      <th>through_date</th>\n",
       "      <th>name</th>\n",
       "      <th>url</th>\n",
       "      <th>filename</th>\n",
       "      <th>page_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Final</td>\n",
       "      <td>2019-04-08</td>\n",
       "      <td>Final 2019 MBB Nitty Gritty</td>\n",
       "      <td>https://extra.ncaa.org/solutions/rpi/Stats%20L...</td>\n",
       "      <td>2019/2019-04-08.pdf</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Selection</td>\n",
       "      <td>2019-03-17</td>\n",
       "      <td>2019 Selections Nitty Gritty</td>\n",
       "      <td>https://extra.ncaa.org/solutions/rpi/Stats%20L...</td>\n",
       "      <td>2019/2019-03-17.pdf</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Current</td>\n",
       "      <td>2019-03-16</td>\n",
       "      <td>NET Nitty Gritty - Games through March 16, 2019</td>\n",
       "      <td>https://extra.ncaa.org/solutions/rpi/Stats%20L...</td>\n",
       "      <td>2019/2019-03-16.pdf</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Current</td>\n",
       "      <td>2019-03-15</td>\n",
       "      <td>NET Nitty Gritty - Games through March 15, 2019</td>\n",
       "      <td>https://extra.ncaa.org/solutions/rpi/Stats%20L...</td>\n",
       "      <td>2019/2019-03-15.pdf</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Current</td>\n",
       "      <td>2019-03-14</td>\n",
       "      <td>NET Nitty Gritty - Games through March 14, 2019</td>\n",
       "      <td>https://extra.ncaa.org/solutions/rpi/Stats%20L...</td>\n",
       "      <td>2019/2019-03-14.pdf</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  report_type through_date                                             name  \\\n",
       "0       Final   2019-04-08                      Final 2019 MBB Nitty Gritty   \n",
       "1   Selection   2019-03-17                     2019 Selections Nitty Gritty   \n",
       "2     Current   2019-03-16  NET Nitty Gritty - Games through March 16, 2019   \n",
       "3     Current   2019-03-15  NET Nitty Gritty - Games through March 15, 2019   \n",
       "4     Current   2019-03-14  NET Nitty Gritty - Games through March 14, 2019   \n",
       "\n",
       "                                                 url             filename  \\\n",
       "0  https://extra.ncaa.org/solutions/rpi/Stats%20L...  2019/2019-04-08.pdf   \n",
       "1  https://extra.ncaa.org/solutions/rpi/Stats%20L...  2019/2019-03-17.pdf   \n",
       "2  https://extra.ncaa.org/solutions/rpi/Stats%20L...  2019/2019-03-16.pdf   \n",
       "3  https://extra.ncaa.org/solutions/rpi/Stats%20L...  2019/2019-03-15.pdf   \n",
       "4  https://extra.ncaa.org/solutions/rpi/Stats%20L...  2019/2019-03-14.pdf   \n",
       "\n",
       "   page_number  \n",
       "0           13  \n",
       "1           13  \n",
       "2           13  \n",
       "3           13  \n",
       "4           13  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-10T18:55:19.710604Z",
     "start_time": "2020-02-10T18:50:00.789482Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No NET in this file: 2019/2019-02-01.pdf\n",
      "No NET in this file: 2019/2019-01-31.pdf\n"
     ]
    }
   ],
   "source": [
    "net_df['col_num'] = net_df.filename.apply(get_net_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-10T18:55:19.723928Z",
     "start_time": "2020-02-10T18:55:19.713030Z"
    }
   },
   "outputs": [],
   "source": [
    "# Add a column of columns\n",
    "col_dict = {}\n",
    "col_dict[12] = ['team', 'net_rank', 'avg_opp_net', 'avg_opp_rank',\n",
    "                'record', 'conf_record', \n",
    "                'non_conf_record', 'road_record'] + \\\n",
    "               [f'quadrant_{i}_record' for i in range(1, 5)]\n",
    "col_dict[14] = ['team', 'net_rank', 'avg_opp_net', 'avg_opp_rank',\n",
    "                'record', 'conf_record', \n",
    "                'non_conf_record', 'road_record', 'sos', 'nc_sos']  + \\\n",
    "               [f'quadrant_{i}_record' for i in range(1, 5)]\n",
    "col_dict[15] = ['', 'team', 'net_rank', 'avg_opp_net', 'avg_opp_rank',\n",
    "                'record', 'conf_record', \n",
    "                'non_conf_record', 'road_record', 'sos', 'nc_sos']  + \\\n",
    "               [f'quadrant_{i}_record' for i in range(1, 5)]\n",
    "net_df['cols'] = net_df['col_num'].map(col_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-10T21:05:24.028081Z",
     "start_time": "2020-02-10T20:01:52.261772Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 pdfs completed.\n",
      "20 pdfs completed.\n",
      "30 pdfs completed.\n",
      "40 pdfs completed.\n",
      "50 pdfs completed.\n",
      "60 pdfs completed.\n",
      "70 pdfs completed.\n",
      "80 pdfs completed.\n",
      "90 pdfs completed.\n"
     ]
    }
   ],
   "source": [
    "start = 1\n",
    "for row in net_df[~net_df.col_num.isna()][['filename', 'page_number', 'cols']].values:\n",
    "    csv_name = row[0].replace('.pdf', '.csv').replace('2019', '2019_clean')\n",
    "    df = get_net_df(row[0], row[1], row[2])\n",
    "    if df.shape != (353, 15):\n",
    "        raise ValueError('Dataframe size should be 353 x 15.')\n",
    "    df.to_csv(csv_name, index=False)\n",
    "    if start % 10 == 0:\n",
    "        print(start, 'pdfs completed.')\n",
    "    start += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-10T21:07:09.562251Z",
     "start_time": "2020-02-10T21:07:09.033644Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overall_net_df = pd.concat([pd.read_csv(fn.replace('.pdf', '.csv').replace('2019', '2019_clean'))\n",
    "                            for fn in net_df[~net_df.col_num.isna()]['filename'].values])\n",
    "overall_net_df.shape[0] == 353 * len(net_df[~net_df.col_num.isna()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-10T21:07:27.204472Z",
     "start_time": "2020-02-10T21:07:27.188569Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>team</th>\n",
       "      <th>net_rank</th>\n",
       "      <th>avg_opp_net</th>\n",
       "      <th>avg_opp_rank</th>\n",
       "      <th>record</th>\n",
       "      <th>conf_record</th>\n",
       "      <th>non_conf_record</th>\n",
       "      <th>road_record</th>\n",
       "      <th>sos</th>\n",
       "      <th>nc_sos</th>\n",
       "      <th>quadrant_1_record</th>\n",
       "      <th>quadrant_2_record</th>\n",
       "      <th>quadrant_3_record</th>\n",
       "      <th>quadrant_4_record</th>\n",
       "      <th>filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Virginia</td>\n",
       "      <td>1</td>\n",
       "      <td>91</td>\n",
       "      <td>40</td>\n",
       "      <td>35-3</td>\n",
       "      <td>17-3</td>\n",
       "      <td>18-0</td>\n",
       "      <td>10-1</td>\n",
       "      <td>18</td>\n",
       "      <td>55</td>\n",
       "      <td>17-3</td>\n",
       "      <td>5-0</td>\n",
       "      <td>6-0</td>\n",
       "      <td>7-0</td>\n",
       "      <td>2019/2019-04-08.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gonzaga</td>\n",
       "      <td>2</td>\n",
       "      <td>129</td>\n",
       "      <td>82</td>\n",
       "      <td>33-4</td>\n",
       "      <td>17-1</td>\n",
       "      <td>16-3</td>\n",
       "      <td>9-1</td>\n",
       "      <td>40</td>\n",
       "      <td>33</td>\n",
       "      <td>6-4</td>\n",
       "      <td>6-0</td>\n",
       "      <td>10-0</td>\n",
       "      <td>11-0</td>\n",
       "      <td>2019/2019-04-08.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Duke</td>\n",
       "      <td>3</td>\n",
       "      <td>79</td>\n",
       "      <td>13</td>\n",
       "      <td>32-6</td>\n",
       "      <td>18-4</td>\n",
       "      <td>14-2</td>\n",
       "      <td>7-2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6 8</td>\n",
       "      <td>13-5</td>\n",
       "      <td>6-1</td>\n",
       "      <td>6-0</td>\n",
       "      <td>7-0</td>\n",
       "      <td>2019/2019-04-08.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Kentucky</td>\n",
       "      <td>4</td>\n",
       "      <td>82</td>\n",
       "      <td>17</td>\n",
       "      <td>30-7</td>\n",
       "      <td>16-5</td>\n",
       "      <td>14-2</td>\n",
       "      <td>8-2</td>\n",
       "      <td>2 5 9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14-6</td>\n",
       "      <td>4-1</td>\n",
       "      <td>7-0</td>\n",
       "      <td>5-0</td>\n",
       "      <td>2019/2019-04-08.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Michigan St.</td>\n",
       "      <td>5</td>\n",
       "      <td>71</td>\n",
       "      <td>6</td>\n",
       "      <td>32-7</td>\n",
       "      <td>20-4</td>\n",
       "      <td>12-3</td>\n",
       "      <td>8-4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31</td>\n",
       "      <td>15-5</td>\n",
       "      <td>7-2</td>\n",
       "      <td>6-0</td>\n",
       "      <td>4-0</td>\n",
       "      <td>2019/2019-04-08.pdf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           team  net_rank  avg_opp_net avg_opp_rank record conf_record  \\\n",
       "0      Virginia         1           91           40   35-3        17-3   \n",
       "1       Gonzaga         2          129           82   33-4        17-1   \n",
       "2          Duke         3           79           13   32-6        18-4   \n",
       "3      Kentucky         4           82           17   30-7        16-5   \n",
       "4  Michigan St.         5           71            6   32-7        20-4   \n",
       "\n",
       "  non_conf_record road_record    sos nc_sos quadrant_1_record  \\\n",
       "0            18-0        10-1     18     55              17-3   \n",
       "1            16-3         9-1     40     33               6-4   \n",
       "2            14-2         7-2    NaN    6 8              13-5   \n",
       "3            14-2         8-2  2 5 9    NaN              14-6   \n",
       "4            12-3         8-4    NaN     31              15-5   \n",
       "\n",
       "  quadrant_2_record quadrant_3_record quadrant_4_record             filename  \n",
       "0               5-0               6-0               7-0  2019/2019-04-08.pdf  \n",
       "1               6-0              10-0              11-0  2019/2019-04-08.pdf  \n",
       "2               6-1               6-0               7-0  2019/2019-04-08.pdf  \n",
       "3               4-1               7-0               5-0  2019/2019-04-08.pdf  \n",
       "4               7-2               6-0               4-0  2019/2019-04-08.pdf  "
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overall_net_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
